{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aiQ0ntBo9L21"
   },
   "source": [
    "# Scraping Reddit Data  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zfmIPcS29L28"
   },
   "source": [
    "<table align=\"left\"><td>\n",
    "  <a target=\"_blank\"  href=\"https://colab.research.google.com/github/TannerGilbert/Tutorials/blob/master/Reddit%20Webscraping%20using%20PRAW/Reddit%20API.ipynb\">\n",
    "    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab\n",
    "  </a>\n",
    "</td><td>\n",
    "  <a target=\"_blank\"  href=\"https://github.com/TannerGilbert/Tutorials/blob/master/Reddit%20Webscraping%20using%20PRAW/Reddit%20API.ipynb\">\n",
    "    <img width=32px src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
    "</td></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qRWeB9Ye9L2-"
   },
   "source": [
    "![](https://www.redditstatic.com/new-icon.png)  \n",
    "Using the PRAW library, a wrapper for the Reddit API, everyone can easily scrape data from Reddit or even create a Reddit bot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AyhGsna29L2_",
    "outputId": "e1571365-a41a-4100-c64b-b7de493cb64e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: praw in /Users/elena/opt/anaconda3/lib/python3.9/site-packages (7.7.1)\n",
      "Requirement already satisfied: prawcore<3,>=2.1 in /Users/elena/opt/anaconda3/lib/python3.9/site-packages (from praw) (2.4.0)\n",
      "Requirement already satisfied: update-checker>=0.18 in /Users/elena/opt/anaconda3/lib/python3.9/site-packages (from praw) (0.18.0)\n",
      "Requirement already satisfied: websocket-client>=0.54.0 in /Users/elena/opt/anaconda3/lib/python3.9/site-packages (from praw) (1.6.4)\n",
      "Requirement already satisfied: requests<3.0,>=2.6.0 in /Users/elena/opt/anaconda3/lib/python3.9/site-packages (from prawcore<3,>=2.1->praw) (2.26.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/elena/opt/anaconda3/lib/python3.9/site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/elena/opt/anaconda3/lib/python3.9/site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/elena/opt/anaconda3/lib/python3.9/site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/elena/opt/anaconda3/lib/python3.9/site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (3.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#!pip install praw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "6fgm3Tez9L3C"
   },
   "outputs": [],
   "source": [
    "import praw\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UuToPGGn9L3C"
   },
   "source": [
    "Before it can be used to scrape data we need to authenticate ourselves. For this we need to create a Reddit instance and provide it with a client_id , client_secret and a user_agent . To create a Reddit application and get your id and secret you need to navigate to [this page](https://www.reddit.com/prefs/apps)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ZvlbJYDx9L3D"
   },
   "outputs": [],
   "source": [
    "reddit = praw.Reddit(client_id='...',\n",
    "                     client_secret='...',\n",
    "                     user_agent='...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ylN6x57Z9L3F"
   },
   "source": [
    "We can get information or posts from a specifc subreddit using the reddit.subreddit method and passing it a subreddit name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "NK1SfK9Y9L3K",
    "outputId": "a6b496e5-0554-47fc-e58c-9b818b099b0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not this year\n",
      "This is NOT going to end well:\n",
      "me_irl\n",
      "Trump (claimed height of 6‚Äô3) standing next to Vivek Ramaswamy (5‚Äô10)\n",
      "These kids are so pure\n",
      "Meanwhile in China\n",
      "Sports Scholarship\n",
      "American Rule\n",
      "Well done ü§£\n",
      "nobody wants to work anymore [oc]\n"
     ]
    }
   ],
   "source": [
    "# get hot posts from all subreddits\n",
    "hot_posts = reddit.subreddit('all').hot(limit=10)\n",
    "for post in hot_posts:\n",
    "    print(post.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "jhCB0df79L3G"
   },
   "outputs": [],
   "source": [
    "# get 10 hot posts from the Pikabu subreddit\n",
    "hot_posts = reddit.subreddit('Pikabu').hot(limit=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DCf3ELI99L3H"
   },
   "source": [
    "Now that we scraped 10 posts we can loop through them and print some information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qLWZyKnC9L3I",
    "outputId": "9f69a717-440a-47b2-c172-7c3419b634aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–í–æ–µ–Ω–Ω–æ–π —Å–∏—Ç—É–∞—Ü–∏–∏ –º–µ–≥–∞—Ç—Ä–µ–¥\n",
      "–ù–æ –∑–∞–ø–∞—Ö! [‚Ä¶] –≠—Ç–æ –±—ã–ª –∑–∞–ø–∞—Ö‚Ä¶ –ø–æ–±–µ–¥—ã!\n",
      "–ù—é–¥—Å—ã –Ω–∞ –∫–∞–∂–¥—ã–π –¥–µ–Ω—å\n",
      "–¶–∏–Ω–∏–∫. –ó–ª–æ–¥–µ–π—Å–∫–æ–µ [—Å–ª–∞–π–¥–µ—Ä]\n",
      "–ö–æ–≥–¥–∞ –Ω–µ –≤ –∫—É—Ä—Å–µ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –Ω–æ–≤–æ—Å—Ç–µ–π.\n",
      "–ë—ã–≤–∞–µ—Ç ¬Ø\\_(„ÉÑ)_/¬Ø\n",
      "–ò–∑–≤–∏–Ω–∏—Ç–µ, –Ω–∞ –Ω–∞—à–∏ 40 —Å–º –Ω–µ –±—ã–ª–æ –∫–∞—Ä—Ç–∏–Ω–∫–∏\n",
      "–†—É–º—ã–Ω—Å–∫–∏–µ –±–∞–Ω–¥–∏—Ç—ã\n",
      "–¢–∞–∫ –Ω–∞—á–∞–ª–æ—Å—å –≤–æ—Å—Å—Ç–∞–Ω–∏–µ –º–∞—à–∏–Ω...\n",
      "–≠—Ç–æ –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –ø—á—ë–ª—ã (—Å)\n"
     ]
    }
   ],
   "source": [
    "for post in hot_posts:\n",
    "    print(post.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the URL of the Reddit post you want to parse\n",
    "post_url = 'https://www.reddit.com/r/Pikabu/comments/110gz4q/–Ω–∞–≥–≥–µ—Ç—Å—ã_–ø—Ä–æ–≤–µ—Ä–µ–Ω–Ω—ã–π_—Ä–µ—Ü–µ–ø—Ç/'\n",
    "\n",
    "# Create a submission object for the post\n",
    "submission = reddit.submission(url=post_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "5ENXiS2V9L3O",
    "outputId": "071cd715-e822-450e-eaa7-e7c3991753b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 1 –∫–≥ –∫—É—Ä–∏–Ω–æ–≥–æ —Ñ–∏–ª–µ \n",
      "- 150–≥. –ø–∞–Ω–∏—Ä–æ–≤–æ—á–Ω—ã—Ö —Å—É—Ö–∞—Ä–µ–π. \n",
      "- 150–≥ –∫—É–∫—É—Ä—É–∑–Ω—ã—Ö —Ö–ª–æ–ø—å–µ–≤.\n",
      "- 2 —Å—Ç.–ª. –∫—É–∫—É—Ä—É–∑–Ω–æ–π –º—É–∫–∏. –õ–∏–±–æ –æ–±—ã—á–Ω–æ–π –ø—à–µ–Ω–∏—á–Ω–æ–π.\n",
      "- 1 —á.–ª. —Å –≥–æ—Ä–∫–æ–π –ø–∞–ø—Ä–∏–∫–∏\n",
      "- 1 —á.–ª. —Å –≥–æ—Ä–∫–æ–π —Å—É—Ö–æ–≥–æ —á–µ—Å–Ω–æ–∫–∞\n",
      "- 3 —á.–ª. —Å –≥–æ—Ä–∫–æ–π —Å–æ–ª–∏\n",
      "- 3/4 —á.–ª. —á–µ—Ä–Ω–æ–≥–æ –ø–µ—Ä—Ü–∞.\n",
      "- 2 —Å—Ç.–ª. –º–æ–ª–æ–∫–∞ –∏–ª–∏ –Ω–µ–∂–∏—Ä–Ω—ã—Ö —Å–ª–∏–≤–æ–∫\n",
      "- 2 —è–π—Ü–∞\n",
      "- —Å–∞—Ö–∞—Ä -2—á.–ª.\n",
      "- —Ä–∞—Å—Ç–∏—Ç–µ–ª—å–Ω–æ–µ –º–∞—Å–ª–æ\n",
      "++++++++++++++++++++++++++++\n",
      "- –ú—è—Å–æ –º–∏–Ω—É—Ç –∑–∞ 20 –∑–∞–±—Ä–æ—Å–∏—Ç—å –≤ –º–æ—Ä–æ–∑–∏–ª–∫—É, —á—Ç–æ–±—ã –µ–≥–æ –ª–µ–≥—á–µ –±—ã–ª–æ –∞–∫–∫—É—Ä–∞—Ç–Ω–æ –Ω–∞—Ä–µ–∑–∞—Ç—å.\n",
      "- –•–ª–æ–ø—å—è –∏–∑–º–µ–ª—å—á–∏—Ç—å –≤ –±–ª–µ–Ω–¥–µ—Ä–µ –ø–æ–∫–∞ –æ–Ω–∏ –Ω–µ —Å—Ç–∞–Ω—É—Ç —Ä–∞–∑–º–µ—Ä–æ–º –ø—Ä–∏–º–µ—Ä–Ω–æ —Å —Ñ—Ä–∞–∫—Ü–∏—é –≤–∞—à–∏—Ö —Å—É—Ö–∞—Ä–µ–π. \n",
      "- –í—Å–µ —Å–ø–µ—Ü–∏–∏ –æ–±—ä–µ–¥–∏–Ω–∏—Ç—å –≤–º–µ—Å—Ç–µ —Å —Å–æ–ª—å—é –∏ –ø–µ—Ä–µ–º–µ—à–∞—Ç—å.\n",
      "- –í –±–æ–ª—å—à–æ–π –º–∏—Å–∫–µ —Å–º–µ—à–∞—Ç—å —Å—É—Ö–∞—Ä–∏, —Ö–ª–æ–ø—å—è, –º—É–∫—É,—Å–∞—Ö–∞—Ä –∏ –ø–æ–ª–æ–≤–∏–Ω—É –ø—Ä—è–Ω–æ—Å—Ç–µ–π —Å —Å–æ–ª—å—é.\n",
      "- –í –¥—Ä—É–≥–æ–π –µ–º–∫–æ—Å—Ç–∏ —Å–º–µ—à–∞—Ç—å —è–π—Ü–∞, –º–æ–ª–æ–∫–æ –∏ –æ—Å—Ç–∞–≤—à—É—é—Å—è –ø–æ–ª–æ–≤–∏–Ω—É –ø—Ä—è–Ω–æ—Å—Ç–µ–π. –ü–µ—Ä–µ–º–µ—à–∞—Ç—å, –Ω–æ –Ω–µ –≤–∑–±–∏–≤–∞—Ç—å.\n",
      "- –ù–∞—Ä–µ–∑–∞—Ç—å –∫—É—Ä–∏–Ω–æ–µ —Ñ–∏–ª–µ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∫—Ä—É–ø–Ω–æ.\n",
      "- –ó–∞–±—Ä–æ—Å–∏—Ç—å –∫—É—Ä–∏—Ü—É –≤ —è–∏—á–Ω—É—é —Å–º–µ—Å—å –∏ —Ö–æ—Ä–æ—à–æ –ø–µ—Ä–µ–º–µ—à–∞—Ç—å, —á—Ç–æ–±—ã –≤—Å–µ –±—ã–ª–æ –ø–æ–∫—Ä—ã—Ç–æ. –û—Å—Ç–∞–≤–∏—Ç—å –º–∏–Ω—É—Ç –Ω–∞ 5.\n",
      "- –ü—Ä–æ—Ç–∏–≤–µ–Ω—å –∑–∞—Å—Ç–µ–ª–∏—Ç—å –ø–µ—Ä–≥–∞–º–µ–Ω—Ç–æ–º. \n",
      "- –ö–∞–∂–¥—ã–π –∫—É—Å–æ–∫ –∫—É—Ä–∏—Ü—ã –∫–∏–¥–∞—Ç—å –≤ –º–∏—Å–∫—É —Å –ø–∞–Ω–∏—Ä–æ–≤–æ—á–Ω–æ–π —Å–º–µ—Å—å—é –∏ —Ö–æ—Ä–æ—à–æ –µ–≥–æ —Ç–∞–º –æ–±–≤–∞–ª—è—Ç—å, –ø—Ä–∏–∂–∏–º–∞—è. \n",
      "- –í—ã–ª–æ–∂–∏—Ç—å –Ω–∞ –ø—Ä–æ—Ç–∏–≤–µ–Ω—å. \n",
      "- –ø–æ–±—Ä—ã–∑–≥–∞—Ç—å –º–∞—Å–ª–æ–º\n",
      "- –ó–∞–ø–µ–∫–∞—Ç—å 18-22 –º–∏–Ω—É—Ç—ã –ø—Ä–∏ 200–°. –ï—Å–ª–∏ –µ—Å—Ç—å –∫–æ–Ω–≤–µ–∫—Ü–∏—è, –≤–∫–ª—é—á–∞–µ–º. –ù–∞–≥—Ä–µ–≤ –≤–µ—Ä—Ö-–Ω–∏–∑\n",
      "–ê –≤–æ—Ç –∏ —Ä–µ—Ü–µ–ø—Ç–∏–∫–∏ –ø–æ—à–ª–∏.\n",
      "–ó–∞–±—Ä–æ—Å–∏–ª –∫—É—Ä–∏—Ü—É –≤ —è–∏—á–Ω—É—é —Å–º–µ—Å—å. –ö—É—Ä–∏—Ü–∞ –æ—Ñ–∏–≥–µ–ª–∞ –∏ —É–±–µ–∂–∞–ª–∞. –ï–ª–µ –ø–æ–π–º–∞–ª. –ü–µ—Ä–µ–º–µ—à–∞—Ç—å –Ω–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å\n",
      "–ë–µ—Ä—ë—à—å –ø—É—á–æ–∫ —É–∫—Ä–æ–ø—É....\n",
      "–ü—Ä–∏—è—Ç–Ω–æ–≥–æ –∞–ø–ø–µ—Ç–∏—Ç–∞. –ù–∞ –≤–∏–¥ –≤—ã–≥–ª—è–¥–∏—Ç –≤–∫—É—Å–Ω–æ!\n",
      "–°–æ—Ö—Ä–∞–Ω–∏–ª üôÉ\n",
      "–¢–∞–∫, –∞ —á—Ç–æ —Ç—ã –µ—â—ë —Å –∫—É—Ä–∏—Ü–µ–π –≤—ã—Ç–≤–æ—Ä—è–µ—à—å? –ï—Å—Ç—å –µ—â–µ —Ä–µ—Ü–µ–ø—Ç—ã?\n",
      "–ö–∞–∫ –≥–æ—Ç–æ–≤–∏—Ç—å –º—è—Å–æ –±–æ–ª–µ–µ –º–µ–Ω–µ–µ —è—Å–Ω–æ, —Å –∫—É—Ä–∏—Ü–µ–π —Ç–∞–∫ –≤–æ–æ–±—â–µ –µ—Å—Ç—å kfc. –ê –≤–æ—Ç —Å–æ—É—Å —ç—Ç–æ —Ü–µ–ª–∞—è –Ω–∞—É–∫–∞. –û–Ω–∏ –∑–∞—á–∞—Å—Ç—É—é –≤ –∫–∞–∂–¥–æ–º –∑–∞–≤–µ–¥–µ–Ω–∏–∏ —Ä–∞–∑–Ω—ã–µ. –¢–∞–∫ —á—Ç–æ –µ—Å–ª–∏ –µ—Å—Ç—å –≥–æ–¥–Ω—ã–µ —Å–æ—É—Å—ã - –¥–∞–≤–∞–π)\n",
      " –°–ø–∞—Å–∏–±–æ, —Å–æ—Ö—Ä–∞–Ω—é –∏ —ç—Ç–æ—Ç —Ç–æ–∂–µ: –∑–∞ —Ä–µ—Ü–µ–ø—Ç —Å–æ—Å–∏—Å–æ–∫ –≤ —Ç–µ—Å—Ç–µ —Ç–æ–∂–µ –æ—Ç–¥–µ–ª—å–Ω–æ–µ —Å–ø–∞—Å–∏–±–æ! –ö–∞–∫ –ø–æ –º–Ω–µ —Ç–µ—Å—Ç–æ –∫–∞–∫–æ–µ-—Ç–æ –Ω–µ —Ç–∞–∫–æ–µ, —è –±—ã –ª—É—á—à–µ —Å –º–æ–ª–æ–∫–æ–º - –ø–æ–ø—Ä–æ–±—É—é —Ç–µ—Å—Ç–æ –∏–∑ —Ä–µ—Ü–µ–ø—Ç–∞ —Ö–∞—á–∞–ø—É—Ä–∏. –î—É–º–∞—é, —á—Ç–æ —Ç–æ–∂–µ –ø–æ–¥–µ–ª—é—Å—å —Ä–µ—Ü–µ–ø—Ç–æ–º —Ö–∞—á–∞–ø—É—Ä–∏, —Ä–∞–∑ —Ç–µ–ø–µ—Ä—å —Ç—É—Ç –∏ —Ä–µ—Ü–µ–ø—Ç—ã –ø–∏—Ö–∞–µ–º :)\n",
      "–Ø –∫—É—Ä–∏–Ω—É—é –≥—Ä—É–¥–∫—É —Ä–µ–∂—É –Ω–∞ –±—Ä—É—Å–æ—á–∫–∏ –ø–æ 1-1,5 —Å–º —Ç–æ–ª—â–∏–Ω–æ–π, –æ–±–≤–∞–ª–∏–≤–∞—é –≤ –º—É–∫–µ (–≤ –º—É–∫–µ —É–∂–µ —Å–æ–ª—å –∏ —Å–ø–µ—Ü–∏–∏), –∑–∞—Ç–µ–º –º–∞–∫–∞—é –≤ —è–π—Ü–æ. –ê –≤ –∫–æ–Ω—Ü–µ –æ–±–≤–∞–ª–∏–≤–∞—é –≤ —á–∏–ø—Å–∞—Ö, –∫–æ—Ç–æ—Ä—ã–µ –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ —Å–∏–ª—å–Ω–æ –∏–∑–º–µ–ª—å—á–∞—é. –ñ–∞—Ä—é –≤ –º–∞—Å–ª–µ. –ú–∞—Å–ª–∞ –Ω–∞–ª–∏–≤–∞—é —Å—Ç–æ–ª—å–∫–æ, —á—Ç–æ–±—ã –±—Ä—É—Å–æ—á–∫–∏ —Å–∫—Ä—ã–≤–∞–ª–æ. –ñ–∞—Ä—è—Ç—Å—è –±—ã—Å—Ç—Ä–æ\n",
      "–ë–ª—è –Ω–∏–∫–æ–≥–¥–∞ —ç—Ç–∞ —Ö—É–π–Ω—è –Ω–µ –Ω—Ä–∞–≤–∏–ª–∞—Å—å. –õ—É—á—à–µ –¢—Ä–∏–ø–ª –í—É–ø–µ—Ä –≤ –ë—É—Ä–≥–µ—Ä –ö–∏–Ω–≥–µ –Ω–∞–≤–µ—Ä–Ω—É—Ç—å\n"
     ]
    }
   ],
   "source": [
    "for top_level_comment in submission.comments:\n",
    "    print(top_level_comment.body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choosing subreddit, number of posts to extract\n",
    "subreddit_name = 'Pikabu'\n",
    "num_posts_to_extract = 1000 \n",
    "\n",
    "all_comments = []\n",
    "\n",
    "# Iterating through the specified number of posts in the subreddit\n",
    "for submission in reddit.subreddit(subreddit_name).new(limit=num_posts_to_extract):\n",
    "    submission.comments.replace_more(limit=None)\n",
    "\n",
    "    # Iterating through the comments and appending them to the all_comments list\n",
    "    for comment in submission.comments.list():\n",
    "        all_comments.append({\n",
    "            'Author': str(comment.author),\n",
    "            'Score': comment.score,\n",
    "            'Comment': comment.body,\n",
    "            'Submission Title': submission.title,\n",
    "        })\n",
    "\n",
    "# Export to a CSV file:\n",
    "df = pd.DataFrame(all_comments)\n",
    "df.to_csv('reddit_comments_pikabu.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author</th>\n",
       "      <th>Score</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Submission Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RECabu</td>\n",
       "      <td>2</td>\n",
       "      <td>–ó–∞–ø–∏—Å–∞–ª –Ω–∞ –≤–∏–¥–µ–æ–∫–∞—Å—Å–µ—Ç—É **[–í–µ—á–Ω–æ–µ —Å–∏—è–Ω–∏–µ —á–∏—Å—Ç–æ...</td>\n",
       "      <td>–ë—É–¥–∏–ª—å–Ω–∏–∫</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SamSamABC1</td>\n",
       "      <td>3</td>\n",
       "      <td>–º–æ–∂–µ—Ç –∫–∞–∫ —ç—Ç–æ? - \\n\\nhttps://preview.redd.it/0...</td>\n",
       "      <td>–í—ã–≥–ª—è–¥–∏—Ç –∑–∞–ª–∏–ø–∞—Ç–µ–ª—å–Ω–æ, –∫–∞–∫ –∫–∞–∫–æ–π-—Ç–æ —Ñ–∏–∑–∏—á–µ—Å–∫–∏–π...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IvanovRomannn</td>\n",
       "      <td>-1</td>\n",
       "      <td>–ù–∞–ø–æ–º–∏–Ω–∞–µ—Ç –Ω–∞—à—É –¥–µ–º–æ–∫—Ä–∞—Ç–∏—é</td>\n",
       "      <td>–í—ã–≥–ª—è–¥–∏—Ç –∑–∞–ª–∏–ø–∞—Ç–µ–ª—å–Ω–æ, –∫–∞–∫ –∫–∞–∫–æ–π-—Ç–æ —Ñ–∏–∑–∏—á–µ—Å–∫–∏–π...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RECabu</td>\n",
       "      <td>1</td>\n",
       "      <td>–ó–∞–ø–∏—Å–∞–ª –Ω–∞ –≤–∏–¥–µ–æ–∫–∞—Å—Å–µ—Ç—É **[–í—Å–ø–æ–º–Ω–∏—Ç—å –≤—Å—ë](http...</td>\n",
       "      <td>–í—ã–≥–ª—è–¥–∏—Ç –∑–∞–ª–∏–ø–∞—Ç–µ–ª—å–Ω–æ, –∫–∞–∫ –∫–∞–∫–æ–π-—Ç–æ —Ñ–∏–∑–∏—á–µ—Å–∫–∏–π...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Initial-Carpenter</td>\n",
       "      <td>1</td>\n",
       "      <td>–ö—Ä–∞—Å–∏–≤–æ–µ</td>\n",
       "      <td>–í—ã–≥–ª—è–¥–∏—Ç –∑–∞–ª–∏–ø–∞—Ç–µ–ª—å–Ω–æ, –∫–∞–∫ –∫–∞–∫–æ–π-—Ç–æ —Ñ–∏–∑–∏—á–µ—Å–∫–∏–π...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Author  Score  \\\n",
       "0             RECabu      2   \n",
       "1         SamSamABC1      3   \n",
       "2      IvanovRomannn     -1   \n",
       "3             RECabu      1   \n",
       "4  Initial-Carpenter      1   \n",
       "\n",
       "                                             Comment  \\\n",
       "0  –ó–∞–ø–∏—Å–∞–ª –Ω–∞ –≤–∏–¥–µ–æ–∫–∞—Å—Å–µ—Ç—É **[–í–µ—á–Ω–æ–µ —Å–∏—è–Ω–∏–µ —á–∏—Å—Ç–æ...   \n",
       "1  –º–æ–∂–µ—Ç –∫–∞–∫ —ç—Ç–æ? - \\n\\nhttps://preview.redd.it/0...   \n",
       "2                         –ù–∞–ø–æ–º–∏–Ω–∞–µ—Ç –Ω–∞—à—É –¥–µ–º–æ–∫—Ä–∞—Ç–∏—é   \n",
       "3  –ó–∞–ø–∏—Å–∞–ª –Ω–∞ –≤–∏–¥–µ–æ–∫–∞—Å—Å–µ—Ç—É **[–í—Å–ø–æ–º–Ω–∏—Ç—å –≤—Å—ë](http...   \n",
       "4                                           –ö—Ä–∞—Å–∏–≤–æ–µ   \n",
       "\n",
       "                                    Submission Title  \n",
       "0                                          –ë—É–¥–∏–ª—å–Ω–∏–∫  \n",
       "1  –í—ã–≥–ª—è–¥–∏—Ç –∑–∞–ª–∏–ø–∞—Ç–µ–ª—å–Ω–æ, –∫–∞–∫ –∫–∞–∫–æ–π-—Ç–æ —Ñ–∏–∑–∏—á–µ—Å–∫–∏–π...  \n",
       "2  –í—ã–≥–ª—è–¥–∏—Ç –∑–∞–ª–∏–ø–∞—Ç–µ–ª—å–Ω–æ, –∫–∞–∫ –∫–∞–∫–æ–π-—Ç–æ —Ñ–∏–∑–∏—á–µ—Å–∫–∏–π...  \n",
       "3  –í—ã–≥–ª—è–¥–∏—Ç –∑–∞–ª–∏–ø–∞—Ç–µ–ª—å–Ω–æ, –∫–∞–∫ –∫–∞–∫–æ–π-—Ç–æ —Ñ–∏–∑–∏—á–µ—Å–∫–∏–π...  \n",
       "4  –í—ã–≥–ª—è–¥–∏—Ç –∑–∞–ª–∏–ø–∞—Ç–µ–ª—å–Ω–æ, –∫–∞–∫ –∫–∞–∫–æ–π-—Ç–æ —Ñ–∏–∑–∏—á–µ—Å–∫–∏–π...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20240 entries, 0 to 20239\n",
      "Data columns (total 4 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   Author            20240 non-null  object\n",
      " 1   Score             20240 non-null  int64 \n",
      " 2   Comment           20240 non-null  object\n",
      " 3   Submission Title  20240 non-null  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 632.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
